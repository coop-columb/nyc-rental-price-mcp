{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Rental Price Prediction Demo\n",
    "\n",
    "This notebook demonstrates the NYC rental price prediction system, from data preprocessing to model training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data\n",
    "\n",
    "First, let's load the sample data and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the sample data\n",
    "sample_data_path = \"../data/raw/sample_listings.csv\"\n",
    "df = pd.read_csv(sample_data_path)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check data types and missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Visualization\n",
    "\n",
    "Let's visualize some key aspects of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Price distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['price'], kde=True)\n",
    "plt.title('Distribution of Rental Prices')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Price by neighborhood\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='neighborhood', y='price', data=df)\n",
    "plt.title('Rental Prices by Neighborhood')\n",
    "plt.xlabel('Neighborhood')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Price vs. bedrooms\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='bedrooms', y='price', data=df)\n",
    "plt.title('Rental Prices by Number of Bedrooms')\n",
    "plt.xlabel('Bedrooms')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Price vs. square footage\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='sqft', y='price', hue='bedrooms', data=df)\n",
    "plt.title('Rental Prices vs. Square Footage')\n",
    "plt.xlabel('Square Footage')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Correlation matrix\n",
    "numeric_cols = ['price', 'bedrooms', 'bathrooms', 'sqft', 'has_doorman', 'has_elevator', \n",
    "                'has_dishwasher', 'has_washer_dryer', 'is_furnished', 'has_balcony', \n",
    "                'has_parking', 'is_no_fee']\n",
    "corr = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Now, let's preprocess the data using our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.nyc_rental_price.data.preprocessing import clean_data, generate_features, split_data\n",
    "from src.nyc_rental_price.features import FeaturePipeline\n",
    "\n",
    "# Clean the data\n",
    "cleaned_df = clean_data(df)\n",
    "print(f\"Cleaned data shape: {cleaned_df.shape}\")\n",
    "\n",
    "# Generate features\n",
    "pipeline = FeaturePipeline()\n",
    "features_df = generate_features(cleaned_df, pipeline)\n",
    "print(f\"Features data shape: {features_df.shape}\")\n",
    "\n",
    "# Display feature columns\n",
    "print(f\"\\nFeature columns:\\n{', '.join(features_df.columns[:20])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split the data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(\n",
    "    features_df, test_size=0.2, val_size=0.1\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "Let's train different models and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.nyc_rental_price.models.model import GradientBoostingModel, NeuralNetworkModel, ModelEnsemble\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "os.makedirs(\"../models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train Gradient Boosting model\n",
    "gb_model = GradientBoostingModel(\n",
    "    model_dir=\"../models\",\n",
    "    model_name=\"gb_demo_model\",\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "gb_metrics = gb_model.evaluate(X_val, y_val)\n",
    "print(f\"Gradient Boosting metrics on validation set:\")\n",
    "for metric, value in gb_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train Neural Network model\n",
    "nn_model = NeuralNetworkModel(\n",
    "    model_dir=\"../models\",\n",
    "    model_name=\"nn_demo_model\",\n",
    "    hidden_layers=[64, 32],\n",
    "    dropout_rate=0.2,\n",
    "    learning_rate=0.001,\n",
    "    epochs=50,\n",
    "    batch_size=8,  # Small batch size for our small dataset\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train, y_train, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate on validation set\n",
    "nn_metrics = nn_model.evaluate(X_val, y_val)\n",
    "print(f\"Neural Network metrics on validation set:\")\n",
    "for metric, value in nn_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create Ensemble model\n",
    "ensemble_model = ModelEnsemble(\n",
    "    models=[gb_model, nn_model],\n",
    "    weights=[0.7, 0.3],  # Weight in favor of the better-performing model\n",
    "    model_dir=\"../models\",\n",
    "    model_name=\"ensemble_demo_model\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Evaluate on validation set\n",
    "ensemble_metrics = ensemble_model.evaluate(X_val, y_val)\n",
    "print(f\"Ensemble metrics on validation set:\")\n",
    "for metric, value in ensemble_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare models on test set\n",
    "models = {\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"Neural Network\": nn_model,\n",
    "    \"Ensemble\": ensemble_model,\n",
    "}\n",
    "\n",
    "test_metrics = {}\n",
    "for name, model in models.items():\n",
    "    metrics = model.evaluate(X_test, y_test)\n",
    "    test_metrics[name] = metrics\n",
    "    print(f\"{name} metrics on test set:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize model performance comparison\n",
    "metrics_df = pd.DataFrame({\n",
    "    model_name: {\n",
    "        'MAE': metrics['mae'],\n",
    "        'RMSE': metrics['rmse'],\n",
    "        'R²': metrics['r2'],\n",
    "    }\n",
    "    for model_name, metrics in test_metrics.items()\n",
    "}).T\n",
    "\n",
    "# Plot MAE and RMSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics_df[['MAE', 'RMSE']].plot(kind='bar')\n",
    "plt.title('Model Error Comparison')\n",
    "plt.ylabel('Error ($)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Plot R²\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics_df['R²'].plot(kind='bar')\n",
    "plt.title('Model R² Comparison')\n",
    "plt.ylabel('R²')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance\n",
    "\n",
    "Let's examine which features are most important for predicting rental prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get feature importances from Gradient Boosting model\n",
    "if hasattr(gb_model, 'feature_importances_'):\n",
    "    # Get top 20 features\n",
    "    feature_importance = gb_model.feature_importances_\n",
    "    top_features = feature_importance.head(20)\n",
    "    \n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x=top_features.values, y=top_features.index)\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Predictions\n",
    "\n",
    "Let's make predictions on some sample properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create sample properties with different characteristics\n",
    "sample_properties = pd.DataFrame([\n",
    "    {\n",
    "        'bedrooms': 1,\n",
    "        'bathrooms': 1,\n",
    "        'sqft': 600,\n",
    "        'neighborhood': 'east village',\n",
    "        'has_doorman': 0,\n",
    "        'has_elevator': 0,\n",
    "        'has_dishwasher': 1,\n",
    "        'has_washer_dryer': 0,\n",
    "        'is_furnished': 0,\n",
    "        'has_balcony': 0,\n",
    "        'has_parking': 0,\n",
    "        'is_no_fee': 1,\n",
    "        'description': 'Cozy 1BR apartment in East Village with dishwasher.'\n",
    "    },\n",
    "    {\n",
    "        'bedrooms': 2,\n",
    "        'bathrooms': 1,\n",
    "        'sqft': 850,\n",
    "        'neighborhood': 'williamsburg',\n",
    "        'has_doorman': 0,\n",
    "        'has_elevator': 1,\n",
    "        'has_dishwasher': 1,\n",
    "        'has_washer_dryer': 0,\n",
    "        'is_furnished': 0,\n",
    "        'has_balcony': 0,\n",
    "        'has_parking': 0,\n",
    "        'is_no_fee': 0,\n",
    "        'description': 'Spacious 2BR in Williamsburg with elevator and dishwasher.'\n",
    "    },\n",
    "    {\n",
    "        'bedrooms': 3,\n",
    "        'bathrooms': 2,\n",
    "        'sqft': 1200,\n",
    "        'neighborhood': 'upper west side',\n",
    "        'has_doorman': 1,\n",
    "        'has_elevator': 1,\n",
    "        'has_dishwasher': 1,\n",
    "        'has_washer_dryer': 1,\n",
    "        'is_furnished': 0,\n",
    "        'has_balcony': 1,\n",
    "        'has_parking': 0,\n",
    "        'is_no_fee': 0,\n",
    "        'description': 'Luxury 3BR/2BA on Upper West Side with doorman, elevator, washer/dryer, and balcony.'\n",
    "    },\n",
    "    {\n",
    "        'bedrooms': 0,\n",
    "        'bathrooms': 1,\n",
    "        'sqft': 450,\n",
    "        'neighborhood': 'astoria',\n",
    "        'has_doorman': 0,\n",
    "        'has_elevator': 0,\n",
    "        'has_dishwasher': 0,\n",
    "        'has_washer_dryer': 0,\n",
    "        'is_furnished': 0,\n",
    "        'has_balcony': 0,\n",
    "        'has_parking': 0,\n",
    "        'is_no_fee': 1,\n",
    "        'description': 'Affordable studio in Astoria. Great location near subway.'\n",
    "    },\n",
    "])\n",
    "\n",
    "# Display sample properties\n",
    "sample_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocess sample properties\n",
    "processed_properties = pipeline.transform(sample_properties)\n",
    "\n",
    "# Make predictions with each model\n",
    "predictions = {}\n",
    "for name, model in models.items():\n",
    "    preds = model.predict(processed_properties)\n",
    "    predictions[name] = preds\n",
    "\n",
    "# Create a DataFrame with predictions\n",
    "results = pd.DataFrame({\n",
    "    'Bedrooms': sample_properties['bedrooms'],\n",
    "    'Bathrooms': sample_properties['bathrooms'],\n",
    "    'Square Feet': sample_properties['sqft'],\n",
    "    'Neighborhood': sample_properties['neighborhood'],\n",
    "})\n",
    "\n",
    "# Add predictions from each model\n",
    "for name, preds in predictions.items():\n",
    "    results[f'{name} Prediction'] = [f\"${p:.2f}\" for p in preds]\n",
    "\n",
    "# Display results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize predictions\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.index = [\n",
    "    f\"{b}BR {n}\" for b, n in zip(\n",
    "        sample_properties['bedrooms'], \n",
    "        sample_properties['neighborhood']\n",
    "    )\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "pred_df.plot(kind='bar')\n",
    "plt.title('Predicted Rental Prices by Model')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Best Model\n",
    "\n",
    "Let's save the best performing model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Determine the best model based on test RMSE\n",
    "best_model_name = min(test_metrics, key=lambda x: test_metrics[x]['rmse'])\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"RMSE: {test_metrics[best_model_name]['rmse']:.2f}\")\n",
    "print(f\"MAE: {test_metrics[best_model_name]['mae']:.2f}\")\n",
    "print(f\"R²: {test_metrics[best_model_name]['r2']:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "best_model.model_name = \"best_model\"\n",
    "best_model.save_model()\n",
    "print(f\"\\nBest model saved as 'best_model'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "Here are some potential next steps for improving the model:\n",
    "\n",
    "1. **Collect more data**: The sample dataset is small. Collecting more listings would improve model performance.\n",
    "\n",
    "2. **Add more features**: Consider adding features like:\n",
    "   - Distance to subway stations\n",
    "   - School district ratings\n",
    "   - Crime statistics\n",
    "   - Walkability scores\n",
    "\n",
    "3. **Hyperparameter tuning**: Use Bayesian optimization to find the optimal hyperparameters for each model.\n",
    "\n",
    "4. **Deploy the API**: Start the FastAPI server to serve predictions:\n",
    "   ```bash\n",
    "   python -m src.nyc_rental_price.api.main\n",
    "   ```\n",
    "\n",
    "5. **Monitor performance**: Implement logging and monitoring to track model performance over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}